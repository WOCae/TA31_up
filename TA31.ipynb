{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing environment and agent...\n",
      "Training for 100 episodes...\n",
      "No existing model found. Starting with a new model.\n",
      "Episode 1: Total reward: -21.99999999999995, Steps: 116\n",
      "Episode 2: Total reward: -2.400000000000001, Steps: 18\n",
      "Episode 3: Total reward: -6.200000000000004, Steps: 37\n",
      "Episode 4: Total reward: -6.800000000000004, Steps: 40\n",
      "Episode 5: Total reward: -1.8000000000000003, Steps: 15\n",
      "Episode 6: Total reward: -1.4, Steps: 13\n",
      "Episode 7: Total reward: -1.8000000000000003, Steps: 15\n",
      "Episode 8: Total reward: -2.2000000000000006, Steps: 17\n",
      "Episode 9: Total reward: -3.000000000000001, Steps: 21\n",
      "Episode 10: Total reward: -3.8000000000000016, Steps: 25\n",
      "Episode 11: Total reward: -1.4, Steps: 13\n",
      "Episode 12: Total reward: -1.4, Steps: 13\n",
      "Episode 13: Total reward: -1.8000000000000003, Steps: 15\n",
      "Episode 14: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 15: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 16: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 17: Total reward: -1.8000000000000003, Steps: 15\n",
      "Episode 18: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 19: Total reward: -1.6, Steps: 14\n",
      "Episode 20: Total reward: -1.4, Steps: 13\n",
      "Episode 21: Total reward: -1.4, Steps: 13\n",
      "Episode 22: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 23: Total reward: -1.4, Steps: 13\n",
      "Episode 24: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 25: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 26: Total reward: -1.4, Steps: 13\n",
      "Episode 27: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 28: Total reward: -1.8000000000000003, Steps: 15\n",
      "Episode 29: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 30: Total reward: -1.8000000000000003, Steps: 15\n",
      "Episode 31: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 32: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 33: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 34: Total reward: -1.4, Steps: 13\n",
      "Episode 35: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 36: Total reward: -1.4, Steps: 13\n",
      "Episode 37: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 38: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 39: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 40: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 41: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 42: Total reward: -1.4, Steps: 13\n",
      "Episode 43: Total reward: -1.1999999999999997, Steps: 12\n",
      "Episode 44: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 45: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 46: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 47: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 48: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 49: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 50: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 51: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 52: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 53: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 54: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 55: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 56: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 57: Total reward: -1.4, Steps: 13\n",
      "Episode 58: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 59: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 60: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 61: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 62: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 63: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 64: Total reward: -1.1999999999999997, Steps: 12\n",
      "Episode 65: Total reward: -1.6, Steps: 14\n",
      "Episode 66: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 67: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 68: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 69: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 70: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 71: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 72: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 73: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 74: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 75: Total reward: -1.1999999999999997, Steps: 12\n",
      "Episode 76: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 77: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 78: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 79: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 80: Total reward: -1.4, Steps: 13\n",
      "Episode 81: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 82: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 83: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 84: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 85: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 86: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 87: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 88: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 89: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 90: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 91: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 92: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 93: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 94: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 95: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 96: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 97: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 98: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 99: Total reward: -0.9999999999999998, Steps: 11\n",
      "Episode 100: Total reward: -0.9999999999999998, Steps: 11\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n",
      "Results saved to asciiFig.txt and model saved to model_weights.json.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import os\n",
    "from collections import deque\n",
    "from math import sqrt\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# #-------------------------------------\n",
    "# フィールドサイズと匂い強度\n",
    "FIELD_SIZE = 8  # フィールドのサイズ\n",
    "SMELL_STRENGTH = 100  # 匂いの強度\n",
    "\n",
    "# エージェントとゴールの初期位置\n",
    "ANT_START = (0, 0)  # エージェントの初期位置\n",
    "GOAL_POSITION = (FIELD_SIZE - 1, FIELD_SIZE - 4)  # ゴール位置\n",
    "\n",
    "# #学習のモニタリング\n",
    "rewards = []\n",
    "# #-------------------------------------\n",
    "\n",
    "# DQNのニューラルネットワーク定義\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "# エージェントの定義\n",
    "class Agent:\n",
    "    def __init__(self, field_size, gamma=0.99, lr = 0.001, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995):\n",
    "        # print(lr)\n",
    "        self.field_size = field_size\n",
    "        self.state_size = field_size ** 2\n",
    "        self.action_size = 4  # 上下左右の4方向\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.model = DQN(self.state_size, self.action_size)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)  # ランダムアクション\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        act_values = self.model(state)\n",
    "        return torch.argmax(act_values[0]).item()  # Q値の最大を選択\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in batch:\n",
    "            state = torch.FloatTensor(state)\n",
    "            next_state = torch.FloatTensor(next_state)\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target += self.gamma * torch.max(self.model(next_state)).item() #Q学習の部分\n",
    "            target_f = self.model(state).detach().clone()\n",
    "            target_f[action] = target\n",
    "            output = self.model(state)\n",
    "            loss = self.criterion(output[action], target_f[action])\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay  # epsilonを減少させる\n",
    "\n",
    "# 環境の定義\n",
    "class Environment:\n",
    "    def __init__(self, field_size, ant_start, goal_position, smell_strength):\n",
    "        self.field_size = field_size\n",
    "        self.ant_position = ant_start\n",
    "        self.goal_position = goal_position\n",
    "        self.smell_strength = 1/smell_strength #入力と逆にする\n",
    "\n",
    "    def calculate_smell(self, position):\n",
    "        \"\"\"ゴールからの匂いの強さを計算\"\"\"\n",
    "        distance = sqrt((position[0] - self.goal_position[0]) ** 2 + (position[1] - self.goal_position[1]) ** 2)\n",
    "        return self.smell_strength / (1 + distance)\n",
    "        # return (1 + distance)/self.smell_strength\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"環境をリセット\"\"\"\n",
    "        self.ant_position = ANT_START\n",
    "        state = np.zeros((self.field_size, self.field_size))\n",
    "        state[self.ant_position] = 1  # エージェントの位置\n",
    "        state[self.goal_position] = self.calculate_smell(self.goal_position)  # ゴール位置の匂い\n",
    "        return state.flatten()\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"アクションを受けて次の状態と報酬を計算\"\"\"\n",
    "        x, y = self.ant_position\n",
    "        if action == 0 and x > 0:  # 上\n",
    "            x -= 1\n",
    "        elif action == 1 and x < self.field_size - 1:  # 下\n",
    "            x += 1\n",
    "        elif action == 2 and y > 0:  # 左\n",
    "            y -= 1\n",
    "        elif action == 3 and y < self.field_size - 1:  # 右\n",
    "            y += 1\n",
    "\n",
    "        # 更新後の位置を保存\n",
    "        new_position = (x, y)\n",
    "\n",
    "        # 無効なアクションを防ぐ\n",
    "        if new_position != self.ant_position:\n",
    "            self.ant_position = new_position\n",
    "\n",
    "        # 次の状態を作成\n",
    "        state = np.zeros((self.field_size, self.field_size))\n",
    "        state[self.ant_position] = 1\n",
    "        state[self.goal_position] = self.calculate_smell(self.goal_position)\n",
    "\n",
    "        # 報酬と終了判定\n",
    "        reward = 1 if self.ant_position == self.goal_position else -0.1\n",
    "        # ゴールに近づいた場合、追加の報酬\n",
    "        if self.ant_position != self.goal_position:\n",
    "            prev_distance = sqrt((x - self.goal_position[0])**2 + (y - self.goal_position[1])**2)\n",
    "            new_distance = sqrt((self.ant_position[0] - self.goal_position[0])**2 + (self.ant_position[1] - self.goal_position[1])**2)\n",
    "            reward += 0.1 if new_distance < prev_distance else -0.1\n",
    "        done = self.ant_position == self.goal_position\n",
    "        return state.flatten(), reward, done\n",
    "\n",
    "\n",
    "# アスキー図を生成する関数\n",
    "def render_ascii(env):\n",
    "    \"\"\"現在の環境状態をアスキー形式で表現（匂いの強さも表示）\"\"\"\n",
    "    grid = [[\"-\"] * env.field_size for _ in range(env.field_size)]\n",
    "    ant_x, ant_y = env.ant_position\n",
    "    goal_x, goal_y = env.goal_position\n",
    "    grid[ant_x][ant_y] = \"A\"  # エージェントの位置\n",
    "    grid[goal_x][goal_y] = \"G\"  # ゴール位置\n",
    "\n",
    "    # 全セルの匂いを計算\n",
    "    smell_map = np.zeros((env.field_size, env.field_size))\n",
    "    for x in range(env.field_size):\n",
    "        for y in range(env.field_size):\n",
    "            smell_map[x, y] = env.calculate_smell((x, y))\n",
    "\n",
    "    # ゴール以外の最大値と最小値を計算\n",
    "    non_goal_smells = [\n",
    "        smell_map[x, y]\n",
    "        for x in range(env.field_size)\n",
    "        for y in range(env.field_size)\n",
    "        if (x, y) != (goal_x, goal_y)\n",
    "    ]\n",
    "    max_smell = max(non_goal_smells)\n",
    "    min_smell = min(non_goal_smells)\n",
    "\n",
    "    # アスキー文字の閾値を設定\n",
    "    thresholds = {\n",
    "        \"@\": max_smell * 0.8,\n",
    "        \"#\": max_smell * 0.6,\n",
    "        \"+\": max_smell * 0.4,\n",
    "        \".\": max_smell * 0.2,\n",
    "        \"-\": min_smell,\n",
    "    }\n",
    "\n",
    "    # 匂いに基づいて文字を割り当て\n",
    "    for x in range(env.field_size):\n",
    "        for y in range(env.field_size):\n",
    "            if (x, y) == (ant_x, ant_y) or (x, y) == (goal_x, goal_y):\n",
    "                continue\n",
    "            smell = smell_map[x, y]\n",
    "            if smell >= thresholds[\"@\"]:\n",
    "                grid[x][y] = \"@\"\n",
    "            elif smell >= thresholds[\"#\"]:\n",
    "                grid[x][y] = \"#\"\n",
    "            elif smell >= thresholds[\"+\"]:\n",
    "                grid[x][y] = \"+\"\n",
    "            elif smell >= thresholds[\".\"]:\n",
    "                grid[x][y] = \".\"\n",
    "            else:\n",
    "                grid[x][y] = \"-\"\n",
    "\n",
    "    # フィールド全体を文字列として返す\n",
    "    return \"\\n\".join([\" \".join(row) for row in grid])\n",
    "\n",
    "# def log_path(env, episode, step, log_path=\"path_log.txt\"):\n",
    "#     \"\"\"エージェントの移動軌跡をログとして保存\"\"\"\n",
    "#     with open(log_path, \"a\") as f:\n",
    "#         ant_x, ant_y = env.ant_position\n",
    "#         goal_x, goal_y = env.goal_position\n",
    "#         f.write(f\"Episode {episode}, Step {step}: Ant at ({ant_x}, {ant_y}), Goal at ({goal_x}, {goal_y})\\n\")\n",
    "\n",
    "def log_smell_correlation(env, action, log_file=\"smell_correlation.txt\"):\n",
    "    \"\"\"アクション選択時の匂い強度をログ\"\"\"\n",
    "    current_smell = env.calculate_smell(env.ant_position)\n",
    "    next_position = env.ant_position\n",
    "    if action == 0 and next_position[0] > 0:  # 上\n",
    "        next_position = (next_position[0] - 1, next_position[1])\n",
    "    elif action == 1 and next_position[0] < env.field_size - 1:  # 下\n",
    "        next_position = (next_position[0] + 1, next_position[1])\n",
    "    elif action == 2 and next_position[1] > 0:  # 左\n",
    "        next_position = (next_position[0], next_position[1] - 1)\n",
    "    elif action == 3 and next_position[1] < env.field_size - 1:  # 右\n",
    "        next_position = (next_position[0], next_position[1] + 1)\n",
    "    next_smell = env.calculate_smell(next_position)\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"Current smell: {current_smell}, Next smell: {next_smell}, Action: {action}\\n\")\n",
    "\n",
    "# 学習ループ\n",
    "def train_agent(episodes, batch_size, save_path=\"asciiFig.txt\", model_save_path=\"model_weights.json\", summary_path=\"episode_summary.txt\"):\n",
    "    # 環境とエージェントの初期化\n",
    "    env = Environment(FIELD_SIZE, ANT_START, GOAL_POSITION, SMELL_STRENGTH)\n",
    "    agent = Agent(FIELD_SIZE)\n",
    "\n",
    "    # 既存のモデルがあれば読み込む\n",
    "    if os.path.exists(model_save_path):\n",
    "        print(f\"Loading existing model from {model_save_path}...\")\n",
    "        \n",
    "        # 学習前のモデルを保存\n",
    "        temp_model = DQN(agent.state_size, agent.action_size)  # 修正: agent の属性を参照\n",
    "        load_model_from_json(temp_model, model_save_path)\n",
    "        \n",
    "        # temp_model の最初の層の重みをプリント　ロードチェック用\n",
    "        # print(\"Weights of the model before training (fc1):\")\n",
    "        # print(temp_model.fc1.weight.data)\n",
    "\n",
    "        # 現在のモデルにロード\n",
    "        load_model_from_json(agent.model, model_save_path)\n",
    "\n",
    "        agent.epsilon = load_model_from_json(agent.model, model_save_path)\n",
    "        load_memory(agent, \"memory.json\")\n",
    "\n",
    "    else:\n",
    "        print(\"No existing model found. Starting with a new model.\")\n",
    "\n",
    "    # アスキー図の保存用ファイルを開く\n",
    "    with open(save_path, \"w\") as ascii_file, open(summary_path, \"w\") as summary_file:\n",
    "        summary_file.write(\"Episode, Total Reward, Steps\\n\")  # サマリーのヘッダー\n",
    "\n",
    "        for episode in range(1, episodes + 1):\n",
    "            state = env.reset()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            step_count = 0\n",
    "\n",
    "            ascii_file.write(f\"Episode {episode}, Step 1\\n\")\n",
    "            ascii_file.write(render_ascii(env) + \"\\n\\n\")  # 初期状態の出力\n",
    "\n",
    "            agent_path = []  # エージェントの経路を記録\n",
    "            smell_correlation_data = []  # 匂い強度と位置の関連データを記録\n",
    "\n",
    "            while not done:\n",
    "                # アクションを選択\n",
    "                action = agent.act(state)\n",
    "                \n",
    "                # 環境を更新\n",
    "                next_state, reward, done = env.step(action)\n",
    "                total_reward += reward\n",
    "                step_count += 1\n",
    "\n",
    "                # 経験を記憶し、学習\n",
    "                agent.remember(state, action, reward, next_state, done)\n",
    "                agent.replay(batch_size)\n",
    "                state = next_state\n",
    "\n",
    "                # ステップごとのアスキー図を保存（終了状態まで）\n",
    "                if not done:\n",
    "                    ascii_file.write(f\"Episode {episode}, Step {step_count + 1}\\n\")\n",
    "                    ascii_file.write(render_ascii(env) + \"\\n\\n\")\n",
    "\n",
    "                agent_path.append(env.ant_position)  # エージェントの現在位置を経路に追加\n",
    "                smell_correlation_data.append((env.ant_position, env.calculate_smell(env.ant_position)))  # 匂いデータを記録\n",
    "\n",
    "\n",
    "            # エピソード終了時の情報を記録\n",
    "            ascii_file.write(f\"Episode {episode} finished after {step_count} steps\\n\\n\")\n",
    "            summary_file.write(f\"{episode}, {total_reward}, {step_count}\\n\")  # サマリーに書き出し\n",
    "\n",
    "            print(f\"Episode {episode}: Total reward: {total_reward}, Steps: {step_count}\")\n",
    "\n",
    "            # モデルをエピソードごとに保存\n",
    "            torch.save(agent.model.state_dict(), model_save_path)\n",
    "\n",
    "            # 学習ループ内でモデル保存\n",
    "            save_model_to_json(agent.model, model_save_path, agent.epsilon)\n",
    "            save_memory(agent, \"memory.json\")\n",
    "        \n",
    "            rewards.append(total_reward)  # 各エピソードの報酬を記録\n",
    "\n",
    "            # エピソード終了時にデータをログ\n",
    "            # log_path(env, episode, step_count)\n",
    "            # log_smell_correlation(episode, smell_correlation_data)\n",
    "\n",
    "        # 報酬の推移をプロット\n",
    "        plt.plot(rewards)\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Reward')\n",
    "        plt.show()\n",
    "\n",
    "        # 学習終了後にポリシーを可視化\n",
    "        # print(\"Visualizing policy...\")\n",
    "        # visualize_policy(agent, env)\n",
    "\n",
    "# def visualize_policy(env, agent):\n",
    "#     \"\"\"各セルにおけるエージェントの方策を可視化\"\"\"\n",
    "#     policy_grid = [[\"-\"] * env.field_size for _ in range(env.field_size)]\n",
    "#     for x in range(env.field_size):\n",
    "#         for y in range(env.field_size):\n",
    "#             position = np.zeros((env.field_size, env.field_size)).flatten()\n",
    "#             position[x * env.field_size + y] = 1\n",
    "#             action = agent.act(position)\n",
    "#             policy_grid[x][y] = [\"↑\", \"↓\", \"←\", \"→\"][action]\n",
    "#     return \"\\n\".join([\" \".join(row) for row in policy_grid])\n",
    "\n",
    "\n",
    "# モデル保存 (テキスト形式)\n",
    "def save_model_to_json(model, file_path, epsilon):\n",
    "    # モデルの状態辞書を取得\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "    # パラメータをJSONに変換\n",
    "    model_dict = {}\n",
    "    for param_tensor in state_dict:\n",
    "        # パラメータのテンソルをリストに変換\n",
    "        model_dict[param_tensor] = state_dict[param_tensor].cpu().numpy().tolist()\n",
    "\n",
    "    # epsilonを保存\n",
    "    model_dict[\"epsilon\"] = epsilon\n",
    "    \n",
    "    # JSONファイルに保存\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(model_dict, f, indent=4)\n",
    "\n",
    "    # print(f\"Model saved to {file_path}.\")\n",
    "\n",
    "\n",
    "# モデル読み込み (テキスト形式)\n",
    "def load_model_from_json(model, file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        model_dict = json.load(f)\n",
    "\n",
    "    # モデルのstate_dictにパラメータをロード\n",
    "    state_dict = {k: torch.tensor(v) for k, v in model_dict.items() if k != \"epsilon\"}\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "    # モデルにパラメータをロード\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(f\"Model loaded from {file_path}.\")\n",
    "\n",
    "    # 最初の層の重みをプリント　ロードチェック用\n",
    "    # print(\"Load Initial weights of fc1 (first layer):\")\n",
    "    # print(model.fc1.weight.data)\n",
    "\n",
    "    # epsilonを復元\n",
    "    epsilon = model_dict.get(\"epsilon\", 1.0)\n",
    "    print(f\"Model loaded from {file_path}. Epsilon: {epsilon}\")\n",
    "    return epsilon\n",
    "\n",
    "\n",
    "# メモリの保存\n",
    "def save_memory(agent, memory_file_path):\n",
    "    # メモリの内容をリストに変換\n",
    "    memory_list = [\n",
    "        [item.tolist() if isinstance(item, np.ndarray) else item for item in experience]\n",
    "        for experience in agent.memory\n",
    "    ]\n",
    "    \n",
    "    # JSON に保存\n",
    "    with open(memory_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(memory_list, f, indent=4)  # インデント追加\n",
    "    # print(f\"Memory saved to {memory_file_path}.\")\n",
    "\n",
    "    # コメント風のフィールドを追加\n",
    "    memory_with_comment = [{\"_comment\": \"Memory format: [state, action, reward, next_state, done]\"}]\n",
    "    memory_with_comment.extend(memory_list)\n",
    "    \n",
    "    with open(memory_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(memory_with_comment, f, indent=4)\n",
    "    # print(f\"Memory saved to {memory_file_path}.\")\n",
    "\n",
    "\n",
    "# メモリの読み込み\n",
    "def load_memory(agent, memory_file_path):\n",
    "    if os.path.exists(memory_file_path):\n",
    "        with open(memory_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            memory_list = json.load(f)\n",
    "\n",
    "        # コメントを除外\n",
    "        memory_list = [item for item in memory_list if not isinstance(item, dict)]\n",
    "\n",
    "        # リストを再度 `deque` に変換し、必要に応じて numpy.ndarray に戻す\n",
    "        agent.memory = deque(\n",
    "            [\n",
    "                [np.array(item) if isinstance(item, list) and isinstance(item[0], float) else item for item in experience]\n",
    "                for experience in memory_list\n",
    "            ],\n",
    "            maxlen=2000\n",
    "        )\n",
    "        print(f\"Memory loaded from {memory_file_path}.\")\n",
    "    else:\n",
    "        print(\"No memory file found. Starting with an empty memory.\")\n",
    "\n",
    "\n",
    "# メイン処理\n",
    "def main():\n",
    "    # 設定\n",
    "    episodes = 100  # 学習エピソード数\n",
    "    batch_size = 32  # ミニバッチサイズ\n",
    "    save_path = \"asciiFig.txt\"  # 学習過程の保存先\n",
    "    model_save_path = \"model_weights.json\"  # 学習モデルの保存先\n",
    "\n",
    "    # 環境とエージェントの初期化\n",
    "    print(\"Initializing environment and agent...\")\n",
    "    env = Environment(FIELD_SIZE, ANT_START, GOAL_POSITION, SMELL_STRENGTH)\n",
    "    agent = Agent(FIELD_SIZE)\n",
    "\n",
    "    # 学習ループの実行\n",
    "    print(f\"Training for {episodes} episodes...\")\n",
    "    train_agent(episodes, batch_size, save_path, model_save_path)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "    print(f\"Results saved to {save_path} and model saved to {model_save_path}.\")\n",
    "\n",
    "    # print(\"Visualizing policy...\")\n",
    "    # visualize_policy(agent, env)\n",
    "    # print(\"Policy visualization complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果ビューアー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "def load_ascii_file(file_path):\n",
    "    \"\"\"asciiFig.txtを読み込んでデータを辞書に変換する関数\"\"\"\n",
    "    data = {}\n",
    "    current_episode = None\n",
    "    current_step = None\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"Episode\") and \"Step\" in line:\n",
    "                parts = line.replace(\",\", \"\").split()\n",
    "                current_episode = int(parts[1])  # エピソード番号\n",
    "                current_step = int(parts[3])  # ステップ番号\n",
    "                if current_episode not in data:\n",
    "                    data[current_episode] = {}\n",
    "                data[current_episode][current_step] = []\n",
    "            elif line.startswith(\"Episode\") and \"finished\" in line:\n",
    "                # 終了行をスキップ\n",
    "                continue\n",
    "            elif current_episode is not None and current_step is not None and line != \"\":\n",
    "                data[current_episode][current_step].append(line)\n",
    "    return data\n",
    "\n",
    "\n",
    "class EpisodeViewerApp(tk.Tk):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.title(\"Episode Viewer\")\n",
    "        self.geometry(\"400x300\")\n",
    "        \n",
    "        self.data = data\n",
    "        self.current_episode = 1\n",
    "        self.current_step = 1\n",
    "\n",
    "        # エピソード選択\n",
    "        tk.Label(self, text=\"Episode:\").grid(row=0, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.episode_var = tk.IntVar(value=1)\n",
    "        self.episode_selector = ttk.Spinbox(self, from_=1, to=len(data), textvariable=self.episode_var, command=self.update_steps)\n",
    "        self.episode_selector.grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "        # ステップ選択（シークバー）\n",
    "        tk.Label(self, text=\"Step:\").grid(row=1, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.step_var = tk.IntVar(value=1)\n",
    "        self.step_slider = ttk.Scale(self, from_=1, to=1, orient=\"horizontal\", variable=self.step_var, command=self.update_display)\n",
    "        self.step_slider.grid(row=1, column=1, padx=5, pady=5, sticky=\"ew\")\n",
    "\n",
    "        # 図の表示エリア\n",
    "        self.display_area = tk.Text(self, wrap=\"none\", width=30, height=10)\n",
    "        self.display_area.grid(row=2, column=0, columnspan=2, padx=5, pady=5)\n",
    "\n",
    "        # 更新ボタン\n",
    "        self.update_button = ttk.Button(self, text=\"Update\", command=self.update_display)\n",
    "        self.update_button.grid(row=3, column=0, columnspan=2, pady=5)\n",
    "\n",
    "        # 初期表示\n",
    "        self.update_steps()\n",
    "\n",
    "    def update_steps(self):\n",
    "        \"\"\"エピソード変更時にステップ数を更新\"\"\"\n",
    "        episode = self.episode_var.get()\n",
    "        if episode in self.data:\n",
    "            max_steps = len(self.data[episode])\n",
    "            self.step_slider.config(to=max_steps)\n",
    "            self.step_var.set(1)\n",
    "            self.update_display()\n",
    "\n",
    "    def update_display(self, *_):\n",
    "        \"\"\"選択されたエピソードとステップに基づいて図を更新\"\"\"\n",
    "        episode = self.episode_var.get()\n",
    "        step = int(self.step_var.get())\n",
    "        if episode in self.data and step in self.data[episode]:\n",
    "            self.display_area.delete(\"1.0\", tk.END)\n",
    "            diagram = \"\\n\".join(self.data[episode][step])\n",
    "            self.display_area.insert(\"1.0\", f\"Episode {episode}, Step {step}\\n\\n{diagram}\")\n",
    "        else:\n",
    "            self.display_area.delete(\"1.0\", tk.END)\n",
    "            self.display_area.insert(\"1.0\", \"No data available for this step.\")\n",
    "\n",
    "# メイン処理\n",
    "if __name__ == \"__main__\":\n",
    "    # ファイルを読み込む\n",
    "    file_path = \"asciiFig.txt\"\n",
    "    # file_path = \"asciiFig_X.txt\"\n",
    "    data = load_ascii_file(file_path)\n",
    "\n",
    "    # アプリケーションを起動\n",
    "    app = EpisodeViewerApp(data)\n",
    "    app.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
